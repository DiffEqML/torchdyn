{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys ; sys.path.append('../')\n",
    "from torchdyn.models import *; from torchdyn import *\n",
    "import torch; import torch.nn as nn; from torch.utils.data import DataLoader; from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl; from pytorch_lightning.loggers import WandbLogger; from pytorch_lightning.metrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "size = 28\n",
    "path_to_data='../data/mnist_data'\n",
    "\n",
    "all_transforms = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(path_to_data, train=True, download=True,\n",
    "                            transform=all_transforms)\n",
    "test_data = datasets.MNIST(path_to_data, train=False,\n",
    "                           transform=all_transforms)\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, pin_memory=True, num_workers=4, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, pin_memory=True, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learner and model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model:nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.iters = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.iters += 1 \n",
    "        x = batch[0] \n",
    "        xtrJ = self.model(x)  \n",
    "        logprob = prior.log_prob(xtrJ[:,1:]).to(x) - xtrJ[:,0] # logp(z_S) = logp(z_0) - \\int_0^S trJ\n",
    "        loss = -torch.mean(logprob)\n",
    "        nde.nfe = 0\n",
    "        return {'loss': loss}   \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr=2e-3, weight_decay=1e-5)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = nn.Sequential(\n",
    "        nn.Linear(2, 64),\n",
    "        nn.Softplus(),\n",
    "        nn.Linear(64, 64),\n",
    "        nn.Softplus(),\n",
    "        nn.Linear(64, 64),\n",
    "        nn.Softplus(),\n",
    "        nn.Linear(64, 2),\n",
    "    )\n",
    "\n",
    "from torch.distributions import MultivariateNormal, Uniform, TransformedDistribution, SigmoidTransform, Categorical\n",
    "prior = MultivariateNormal(torch.zeros(2).to(device), torch.eye(2).to(device)) \n",
    "\n",
    "# stochastic estimators require a definition of a distribution where \"noise\" vectors are sampled from\n",
    "noise_dist = MultivariateNormal(torch.zeros(2).to(device), torch.eye(2).to(device))\n",
    "# cnf wraps the net as with other energy models\n",
    "cnf = CNF(f, trace_estimator=hutch_trace, noise_dist=noise_dist)\n",
    "nde = NeuralDE(cnf, solver='dopri5', s_span=torch.linspace(0, 1, 2), sensitivity='adjoint', atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(Augmenter(augment_idx=1, augment_dims=1),\n",
    "                      nde).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(max_epochs=600)\n",
    "trainer.fit(learn);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
