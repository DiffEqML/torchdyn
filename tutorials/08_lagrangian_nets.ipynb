{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagrangian Neural Networks\n",
    "\n",
    "In this tutorial we take a look at **Lagrangian Nets** (LNNs) first proposed in [Lutter M., et al, 2019](https://arxiv.org/abs/1907.04490) and generalized by [Cranmer M., et al., 2020](https://arxiv.org/abs/2003.04630). Together with HNNs [Greydanus S., et al., 2019](https://arxiv.org/abs/1906.01563), LNNs represent the latest learning paradigm to discover symmetries and conservation laws from data.\n",
    "\n",
    "Let $\\mathcal{Q}\\subset\\mathbb{R}^n$ be a smooth manifold anf let $q\\in\\mathcal{Q}$ be a vector of generalized coordinates. The Lagrangian function $\\mathcal{L}:\\mathcal{TQ}\\rightarrow\\mathbb{R}$ is defined on the tangent bundle $\\mathcal{TQ}$ of the configuration manifold $\\mathcal{Q}$ (if $\\mathcal{Q}=\\mathbb{R}^n$, then $\\mathcal{TQ}$ is diffeomorphic to $\\mathbb{R}^{2n}$), i.e. the Lagrangian is a function of the configurations $q$ and their velocities $\\dot q$. \n",
    "\n",
    "Derived from the calculus of variations, the Euler-Lagrange equations of motions can be generally explicitly written as a second--order ordinary differential equation:\n",
    "\n",
    "$$\n",
    "    \\ddot q = \\left(\\nabla_{\\dot q} \\nabla_{\\dot q}^\\top \\mathcal{L}\\right)^{-1}\\left[\\nabla_q\\mathcal{L} - \\left(\\nabla_q\\nabla^\\top_{\\dot q}\\mathcal L\\right)\\dot q\\right]\n",
    "$$\n",
    "\n",
    "**Lagrangian Neural Networks** try to mimick Euler-Lagrange equations by learning from data a Lagrangian $\\mathcal{L}_\\theta$ parametriezed by a *neural network* (with parameters $\\theta$). \n",
    "\n",
    "When a net of tuples $\\{(q_k,\\dot q_k, \\ddot q_k)\\}_{k=1,\\dots,K}$ generated by some conservative dynamical process is available, LNNs are trained to learn the Lagrangian from the data by minimizing, e.g. the *MSE loss*:\n",
    "$$\n",
    "    \\min_{\\theta}\\frac{1}{K}\\sum_{k=1}^K\\left\\|\\ddot q_k - \\left(\\nabla_{\\dot q} \\nabla_{\\dot q}^\\top \\mathcal{L}_\\theta(q_k, \\dot q_k)\\right)^{-1}\\left[\\nabla_q\\mathcal{L}_\\theta(q_k, \\dot q_k) - \\left(\\nabla_q\\nabla^\\top_{\\dot q}\\mathcal L_\\theta(q_k, \\dot q_k)\\right)\\dot q_k\\right]\\right\\|_2^2\n",
    "$$\n",
    "\n",
    "\n",
    "We hereby showcase the torchdyn implementation of LNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from torchdyn.models import *; from torchdyn.datasets import *\n",
    "from torchdyn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector field of an LNN, to be passed to a `NeuralDE` can be defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.functional import jacobian, hessian ; from functools import partial\n",
    "\n",
    "class LNN(nn.Module):\n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "    def forward(self, x):\n",
    "        self.n = n = x.shape[1]//2 ; bs = x.shape[0]   \n",
    "        x = torch.autograd.Variable(x, requires_grad=True)\n",
    "        qqd_batch = tuple(x[i, :] for i in range(bs))\n",
    "        jac = tuple(map(partial(jacobian, self._lagrangian, create_graph=True), qqd_batch))\n",
    "        hess = tuple(map(partial(hessian, self._lagrangian, create_graph=True), qqd_batch))\n",
    "        qdd_batch = tuple(map(self._qdd, zip(jac, hess, qqd_batch)))\n",
    "        qd, qdd = x[:, n:], torch.cat([qdd[None] for qdd in qdd_batch])\n",
    "        return torch.cat([qd, qdd], 1)\n",
    "    \n",
    "    def _lagrangian(self, qqd):\n",
    "        return self.net(qqd).sum()\n",
    "    \n",
    "    def _qdd(self, inp):\n",
    "        n = self.n ; jac, hess, qqd = inp\n",
    "        return hess[n:, n:].pinverse()@(jac[:n] - hess[n:, :n]@qqd[n:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a 1D pendulum with torsional spring\n",
    "\n",
    "$$\n",
    "    m\\ddot x - kx - mgl\\sin(x) = 0\n",
    "$$\n",
    "\n",
    "Following the LNN paper from Cranmer et al., we generate random values of $x,\\dot x$ and we fit (in a static manner) the corresponding $\\ddot q$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Static\" Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "m, k, l, g = 1, 1, 1, 9.81\n",
    "X = torch.randn(1000,2).to(device)\n",
    "Xdd = -k*X[:,0]/m - m*g*l*torch.sin(X[:,0])\n",
    "\n",
    "train = data.TensorDataset(X, Xdd)\n",
    "trainloader = data.DataLoader(train, batch_size=len(X)//10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model:nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model.defunc(0, x)\n",
    "    \n",
    "    def loss(self, y_hat, y):\n",
    "        return ((y - y_hat[:,1])**2).mean()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model.defunc(0, x) # static training: we do not solve the ODE \n",
    "        loss = self.loss(y_hat, y)\n",
    "        return {'loss': loss}   \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=0.0001)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LNN(nn.Sequential(\n",
    "            nn.Linear(2,64),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64,64),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64,1))\n",
    "         ).to(device)\n",
    "\n",
    "model = NeuralDE(func=net, solver='dopri5').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "  | Name                 | Type       | Params\n",
      "------------------------------------------------\n",
      "0 | model                | NeuralDE   | 4 K   \n",
      "1 | model.defunc         | DEFunc     | 4 K   \n",
      "2 | model.defunc.m       | LNN        | 4 K   \n",
      "3 | model.defunc.m.net   | Sequential | 4 K   \n",
      "4 | model.defunc.m.net.0 | Linear     | 192   \n",
      "5 | model.defunc.m.net.1 | Softplus   | 0     \n",
      "6 | model.defunc.m.net.2 | Linear     | 4 K   \n",
      "7 | model.defunc.m.net.3 | Softplus   | 0     \n",
      "8 | model.defunc.m.net.4 | Linear     | 65    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24741d2b602e4546aa1890f30717af05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefano\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\warnings.py:18: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=500, max_epochs=1000)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the training results\n",
    "import time\n",
    "t = time.time()\n",
    "model.nfe = 0\n",
    "X0 = torch.Tensor(256, 2).uniform_(-1,1).to(device)\n",
    "s_span = torch.linspace(0, 1, 100)\n",
    "traj = model.trajectory(X0, s_span).cpu().detach()\n",
    "T = time.time() - t\n",
    "print(f\"NFE: {model.nfe}\\ninference time: {T}\\navg time per function evaluation: {T/model.nfe}\")\n",
    "# the inference time to compute a full trajectory is currently still quite high and scales with the batch. We are aware of this issue and we will release an accellerated version soon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the HHN's trajectories with random ICs\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax = fig.add_subplot(111)\n",
    "color = ['orange', 'blue']\n",
    "for i in range(len(X0)):\n",
    "    ax.plot(traj[:,i,0], traj[:,i,1], color='blue', alpha=0.1);\n",
    "#ax.plot(X[:,0].cpu(),X[:,1].cpu(), color='red')\n",
    "ax.set_xlim([-1,1])\n",
    "ax.set_ylim([-4,4])\n",
    "ax.set_xlabel(r\"$q$\")\n",
    "ax.set_ylabel(r\"$p$\")\n",
    "ax.set_title(\"HHN's trajectories & training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grid =  50\n",
    "x = torch.linspace(-3,3,n_grid)\n",
    "Q, P = torch.meshgrid(x,x)\n",
    "H, U, V = torch.zeros(Q.shape), torch.zeros(Q.shape), torch.zeros(Q.shape)\n",
    "for i in range(n_grid):\n",
    "    for j in range(n_grid):\n",
    "        x = torch.cat([Q[i,j].reshape(1,1),P[i,j].reshape(1,1)],1).to(device)\n",
    "        H[i,j] = model.defunc.m.net(x).detach().cpu()\n",
    "        O = model.defunc(0,x).detach().cpu()\n",
    "        U[i,j], V[i,j] = O[0,0], O[0,1]\n",
    "        \n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.contourf(Q,P,H,100,cmap='RdYlBu')\n",
    "ax.streamplot(Q.T.numpy(),P.T.numpy(),U.T.numpy(),V.T.numpy(), color='black')\n",
    "ax.set_xlim([Q.min(),Q.max()])\n",
    "ax.set_ylim([P.min(),P.max()])\n",
    "ax.set_xlabel(r\"$q$\")\n",
    "ax.set_ylabel(r\"$p$\")\n",
    "ax.set_title(\"Learned Lagrangian & Vector Field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
