{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7991fe96",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [8]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e02a8",
   "metadata": {
    "papermill": {
     "duration": 0.024543,
     "end_time": "2021-06-17T12:39:24.039027",
     "exception": false,
     "start_time": "2021-06-17T12:39:24.014484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The Cookbook of Neural ODEs\n",
    "\n",
    "Torchdyn implements out-of-the-box a variety of continuous-depth models. In this introductory tutorial, we show how we can switch between model variants with minor effort. We will touch upon the following Neural ODE variants:\n",
    "\n",
    "* **Vanilla** (depth-invariant) (same as the [torchdyn quickstart](./00_quickstart.html) tutorial)\n",
    "* **Vanilla** (depth-variant)\n",
    "* **Galerkin**\n",
    "* **Data-controlled**\n",
    "* **Stacked (piece-wise constant weights)**\n",
    "* **Stacked with discrete state transitions**\n",
    "--------------------------------------\n",
    "\n",
    "For more advanced models check out \n",
    "\n",
    "* [Hamiltonian Neural Networks](./06a_hamiltonian_nn.html)\n",
    "* [Lagrangian Neural Networks](./06b_lagrangian_nn.html)\n",
    "* [Continuous Normalizing Flow](./07_continuous_normalizing_flow.html)\n",
    "* [Graph Neural ODEs](./08_graph_neural_de.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9491fa67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T12:39:24.083794Z",
     "iopub.status.busy": "2021-06-17T12:39:24.083523Z",
     "iopub.status.idle": "2021-06-17T12:39:25.175329Z",
     "shell.execute_reply": "2021-06-17T12:39:25.175759Z"
    },
    "papermill": {
     "duration": 1.118505,
     "end_time": "2021-06-17T12:39:25.175944",
     "exception": false,
     "start_time": "2021-06-17T12:39:24.057439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchdyn.core import NeuralODE\n",
    "from torchdyn.nn import DataControl, DepthCat, Augmenter, GalLinear, Fourier\n",
    "from torchdyn.datasets import *\n",
    "from torchdyn.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6727b",
   "metadata": {
    "papermill": {
     "duration": 0.018588,
     "end_time": "2021-06-17T12:39:25.218468",
     "exception": false,
     "start_time": "2021-06-17T12:39:25.199880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data:** we use again the moons dataset (with some added noise) simply because all the models will be effective to solve this easy binary classification problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d87b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T12:39:25.258441Z",
     "iopub.status.busy": "2021-06-17T12:39:25.257338Z",
     "iopub.status.idle": "2021-06-17T12:39:25.260573Z",
     "shell.execute_reply": "2021-06-17T12:39:25.260294Z"
    },
    "papermill": {
     "duration": 0.023454,
     "end_time": "2021-06-17T12:39:25.260625",
     "exception": false,
     "start_time": "2021-06-17T12:39:25.237171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = ToyDataset()\n",
    "X, yn = d.generate(n_samples=512, dataset_type='moons', noise=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34745a9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T12:39:25.312065Z",
     "iopub.status.busy": "2021-06-17T12:39:25.308136Z",
     "iopub.status.idle": "2021-06-17T12:39:28.274553Z",
     "shell.execute_reply": "2021-06-17T12:39:28.274100Z"
    },
    "papermill": {
     "duration": 2.995151,
     "end_time": "2021-06-17T12:39:28.274655",
     "exception": false,
     "start_time": "2021-06-17T12:39:25.279504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['orange', 'blue'] \n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(len(X)):\n",
    "    ax.scatter(X[i,0], X[i,1], s=1, color=colors[yn[i].int()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8e0a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T12:39:28.360664Z",
     "iopub.status.busy": "2021-06-17T12:39:28.360139Z",
     "iopub.status.idle": "2021-06-17T12:39:32.805435Z",
     "shell.execute_reply": "2021-06-17T12:39:32.804953Z"
    },
    "papermill": {
     "duration": 4.507785,
     "end_time": "2021-06-17T12:39:32.805540",
     "exception": false,
     "start_time": "2021-06-17T12:39:28.297755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train = torch.Tensor(X).to(device)\n",
    "y_train = torch.LongTensor(yn.long()).to(device)\n",
    "train = data.TensorDataset(X_train, y_train)\n",
    "trainloader = data.DataLoader(train, batch_size=len(X), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3e0216",
   "metadata": {
    "papermill": {
     "duration": 0.019241,
     "end_time": "2021-06-17T12:39:32.846486",
     "exception": false,
     "start_time": "2021-06-17T12:39:32.827245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Learner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c27ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T12:39:32.891810Z",
     "iopub.status.busy": "2021-06-17T12:39:32.891491Z",
     "iopub.status.idle": "2021-06-17T12:39:32.893499Z",
     "shell.execute_reply": "2021-06-17T12:39:32.893735Z"
    },
    "papermill": {
     "duration": 0.027901,
     "end_time": "2021-06-17T12:39:32.893799",
     "exception": false,
     "start_time": "2021-06-17T12:39:32.865898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model:nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch      \n",
    "        y_hat = self.model(x)   \n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}   \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=0.005)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d950f69",
   "metadata": {
    "papermill": {
     "duration": 0.019388,
     "end_time": "2021-06-17T12:39:32.936640",
     "exception": false,
     "start_time": "2021-06-17T12:39:32.917252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Note:** In this notebook we will consider the depth domain $[0,1]$, i.e. $s\\in[0,1]$. Note that, for most architectures in *static* settings (aka we do not deal with dynamic data) any other depth domain does not actually affect the expressiveness of Neural ODEs, since it can be seen as a rescaled/shifted version of $[0,1]$. Please note that, however, other choices of the depth domain can indeed affect the training phase\n",
    "\n",
    "The depth domain can be accessed and modified through the `s_span` setting of `NeuralDE` instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febbd1bb",
   "metadata": {
    "papermill": {
     "duration": 0.019488,
     "end_time": "2021-06-17T12:39:32.975753",
     "exception": false,
     "start_time": "2021-06-17T12:39:32.956265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Vanilla Neural ODE (Depth-Invariant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf9358",
   "metadata": {
    "papermill": {
     "duration": 0.019643,
     "end_time": "2021-06-17T12:39:33.014980",
     "exception": false,
     "start_time": "2021-06-17T12:39:32.995337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$ \\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\dot{z}(s) &= f(z(s), \\theta)\\\\\n",
    "        z(0) &= x\\\\\n",
    "        \\hat y & = z(1)\n",
    "    \\end{aligned}\n",
    "    \\right. \\quad s\\in[0,1]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bc4ae",
   "metadata": {
    "papermill": {
     "duration": 0.019468,
     "end_time": "2021-06-17T12:39:33.054014",
     "exception": false,
     "start_time": "2021-06-17T12:39:33.034546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This model is the same used in [torchdyn quickstart](./00_quickstart.html) tutorial. The vector field is parametrized by a neural network $f$ with *static* parameters $\\theta$ and taking as input only the state $h(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64fc48d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T12:39:33.097154Z",
     "iopub.status.busy": "2021-06-17T12:39:33.096838Z",
     "iopub.status.idle": "2021-06-17T12:39:33.108035Z",
     "shell.execute_reply": "2021-06-17T12:39:33.107521Z"
    },
    "papermill": {
     "duration": 0.03442,
     "end_time": "2021-06-17T12:39:33.108134",
     "exception": false,
     "start_time": "2021-06-17T12:39:33.073714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vector field parametrized by a NN\n",
    "f = nn.Sequential(\n",
    "        nn.Linear(2, 64),\n",
    "        nn.Tanh(), \n",
    "        nn.Linear(64, 2))\n",
    "\n",
    "# Neural ODE\n",
    "model = NeuralODE(f, sensitivity='adjoint', solver='dopri5').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35039c06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T12:39:33.154937Z",
     "iopub.status.busy": "2021-06-17T12:39:33.154670Z",
     "iopub.status.idle": "2021-06-17T12:39:49.371981Z",
     "shell.execute_reply": "2021-06-17T12:39:49.372215Z"
    },
    "papermill": {
     "duration": 16.239834,
     "end_time": "2021-06-17T12:39:49.372314",
     "exception": false,
     "start_time": "2021-06-17T12:39:33.132480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | NeuralODE | 322   \n",
      "------------------------------------\n",
      "322       Trainable params\n",
      "0         Non-trainable params\n",
      "322       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d08adc32d0462b978dec2b6ba1daa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the Neural ODE\n",
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=200, max_epochs=250, progress_bar_refresh_rate=1)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925db541",
   "metadata": {
    "papermill": {
     "duration": 0.020305,
     "end_time": "2021-06-17T12:39:49.413997",
     "exception": false,
     "start_time": "2021-06-17T12:39:49.393692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738882df",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b00a6cc",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-17T12:39:49.457977Z",
     "iopub.status.busy": "2021-06-17T12:39:49.457643Z",
     "iopub.status.idle": "2021-06-17T12:39:49.622907Z",
     "shell.execute_reply": "2021-06-17T12:39:49.623605Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.18947,
     "end_time": "2021-06-17T12:39:49.623851",
     "exception": true,
     "start_time": "2021-06-17T12:39:49.434381",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py:296: UserWarning: t is not on the same device as y0. Coercing to y0.device.\n",
      "  warnings.warn(\"t is not on the same device as y0. Coercing to y0.device.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d1b3fbbd9cff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the data trajectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_span\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/libraries/torchdyn/torchdyn/core/neuralde.py\u001b[0m in \u001b[0;36mtrajectory\u001b[0;34m(self, x, s_span)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[1;32m    180\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prep_odeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         sol = torchdiffeq.odeint(self.defunc, x, s_span,\n\u001b[0m\u001b[1;32m    182\u001b[0m                                  rtol=self.rtol, atol=self.atol, **self.solver)\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_before_integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             first_step = _select_initial_step(self.func, t[0], self.y0, self.order - 1, self.rtol, self.atol,\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# Do nothing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/torchdyn/torchdyn/core/defunc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhorder_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)"
     ]
    }
   ],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,100)\n",
    "trajectory = model.trajectory(X_train, s_span).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373fa227",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ad5e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99881711",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda74ad8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Vanilla Neural ODE (Depth-Variant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78389a6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "$$ \\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\dot{z}(s) &= f(s, z(s), \\theta)\\\\\n",
    "        z(0) &= x\\\\\n",
    "        \\hat y & = z(1)\n",
    "    \\end{aligned}\n",
    "    \\right. \\quad s\\in[0,1]\n",
    "$$\n",
    "\n",
    "This model, contemplated by the seminal paper from [[Chen T. Q. et al, 2018]](https://arxiv.org/abs/1806.07366), is usually obtained by concatenating $s$ to the state $h$ as input of $f$, i.e. $f([h(s),s])$. For a simple and flexible implementation we developed a dedicated layer, `DepthCat`, which takes care of automatically concatenating $s$ to the state at each call of the `DEFunc`. The final user only needs to specify concatenation dimension to which $s$ should be appended. Specifically, for an MLP, $h\\in\\mathbb{R}^{batch\\times dims}$ and, thus we should use `DepthCat(1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948171a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vector field parametrized by a NN\n",
    "f = nn.Sequential(\n",
    "        DepthCat(1),\n",
    "        nn.Linear(2+1, 64),\n",
    "        nn.Tanh(),\n",
    "        DepthCat(1),\n",
    "        nn.Linear(64+1, 2))\n",
    "\n",
    "# Neural ODE\n",
    "model = NeuralODE(f, sensitivity='adjoint', solver='dopri5').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023be3c1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train the Neural ODE\n",
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=200, max_epochs=250, progress_bar_refresh_rate=1)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ac7c22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1799b95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,100)\n",
    "trajectory = model.trajectory(X_train, s_span).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c770d5f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87e98d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e69af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8dad83",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Galerkin-Style Neural ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a7b4b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Galerkin-style Neural ODEs proposed in [Massaroli S., Poli M. et al., 2020](https://arxiv.org/abs/2002.08071) make the weights of the neural ODE to be *depth-varying*, i.e. $\\theta=\\theta(s)$ obtaining a model of type\n",
    "\n",
    "$$\n",
    "    \\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\dot{z}(s) &= f(z(s), \\theta(s))\\\\\n",
    "        z(0) &= x\\\\\n",
    "        \\hat y & = z(1)\n",
    "    \\end{aligned}\n",
    "    \\right. \\quad s\\in[0,1]\n",
    "$$\n",
    "\n",
    "where the depth evolution of $\\theta(s)$ is parametrized by a trucated eigenfunction expasion, usually an orthogonal basis of some functional space, i.e.\n",
    "\n",
    "$$\n",
    "    \\forall i \\quad \\theta_i(s) = \\sum_{j=0}^{m}\\gamma_j\\odot\\psi_j(s)\n",
    "$$\n",
    "\n",
    "The model is then trained by optimizing for the eigenvalues $\\gamma_j$. Note that if $\\theta\\in \\mathbb{R}^d$ there will be $d\\times m$ final model's parameters. In this tutorial, we use a 10th-order polynomial expansion to model $\\theta(s)$.\n",
    "\n",
    "**Note:** In `torchdyn 0.1.0` only Fourier `FourierExpansion` and polynomial `PolyExpansion` bases are currently implemented out-of-the-box. Even though a wider selection of bases is planned as a future addition, e.g.  piece-wise constant functions, radial basis functions, etc., users can easily create custom `Expansions` on their own given `torchdyn`'s modular design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4356c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vector field parametrized by a NN with \"GalLinear\" layer\n",
    "# notice how DepthCat is still used since Galerkin layers make use of `s` (though in a different way compared to concatenation)\n",
    "f = nn.Sequential(DepthCat(1), \n",
    "                  GalLinear(2, 32, expfunc=Fourier(5)),\n",
    "                  nn.Tanh(),\n",
    "                  nn.Linear(32, 2))\n",
    "# neural ODE\n",
    "model = NeuralODE(f, sensitivity='adjoint', solver='dopri5').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1820e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train the Neural ODE\n",
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=150, max_epochs=200, progress_bar_refresh_rate=1)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97de73e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce713a9c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,100)\n",
    "trajectory = model.trajectory(X_train, s_span).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec32e29",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374faa01",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8498dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e92e2af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Data-Controlled Neural ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45b692",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Data-controlled neural ODEs, also introduced in [Massaroli S., Poli M. et al., 2020](https://arxiv.org/abs/2002.08071) consist in feeding to the vector field the input data $x$ (the initial condition of the ODE), leading to\n",
    "\n",
    "$$ \\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\dot{z}(s) &= f(z(s), x, \\theta)\\\\\n",
    "        z(0) &= x\\\\\n",
    "        \\hat y & = z(1)\n",
    "    \\end{aligned}\n",
    "    \\right. \\quad s\\in[0,1]\n",
    "$$\n",
    "\n",
    "In this way, the Neural ODE learns a family of vector fields rather than a single one. \n",
    "\n",
    "In practice, we concatenate $x$ to $h$ and simply feed $[h, x]$ to $f$, which should indeed be defined to accomodate the extra $dim(x)$ dimensions. Data-control inputs can be defined at any point in `f` via use of `DataControl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad40c73",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vector field parametrized by a NN which takes as input [h, x]\n",
    "f = nn.Sequential(DataControl(),\n",
    "                  nn.Linear(2+2, 64),\n",
    "                  nn.Tanh(),\n",
    "                  nn.Linear(64, 2))\n",
    "\n",
    "# neural ODE\n",
    "model = NeuralODE(f, sensitivity='adjoint', solver='dopri5').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c82a9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=150, max_epochs=250)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8addfa2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e6d9a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,100)\n",
    "trajectory = model.trajectory(X_train, s_span).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0772ba5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6196863",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f0f221",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5173abc8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Stacked Neural ODE (aka Piece-wise constant parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b182d60",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "While looking for an \"easier\" solution than Galererkin Neural ODEs without trading the expressivity of the model, **stacked neural ODEs** may come in handy. Instead of approximating the solution of an infinite-dimensional problem (e.g. Galerkin-style), we can also use piece-wise constant weight functions. Let us subdivide the depth in $N$ intervals\n",
    "    \n",
    "$$\n",
    "        \\mathcal{S} = \\prod_{i=0}^{N}[s_i,s_{i+1}], \\quad s_0 = 0, \\quad s_{N+1}=S  \\quad(\\forall i  \\quad s_i\\leq s_{i+1})\n",
    "$$\n",
    "\n",
    "We can then define the weights as piece-wise constant functions \n",
    "\n",
    "$$\n",
    "        \\forall i  \\quad s\\in[s_i,s_{i+1}]\\Rightarrow\\theta(s) = \\theta_i, \\quad\\theta_i\\in\\{\\theta_1,\\theta_2,\\theta_N\\}\n",
    "$$\n",
    "    \n",
    "The solution of the neural ODE becomes \n",
    "    \n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        z(s) &= x + \\int_0^S f(z(\\tau),\\theta(\\tau))d\\tau \\\\\n",
    "        &= x + \\sum_{i=1}^{N-1}\\int_{s_i}^{s_{i+1}} f(z(\\tau),\\theta_i)d\\tau\n",
    "    \\end{aligned}\n",
    "$$\n",
    "    \n",
    "This is equivalent to stacking $N-1$ neural ODEs with **identical structure** and **disentangled weights**\n",
    "    \n",
    "$$\n",
    "        \\begin{aligned}\n",
    "         \\dot z =  f( z(s),\\theta_i) \\quad s\\in[s_i,s_{i+1}]\n",
    "        \\end{aligned}\n",
    "$$\n",
    "    \n",
    "which are **stacked sequentially** and trained with *classic* adjoint method.\n",
    "\n",
    "In principle, $f$ can be chosen arbitrarily. Hereafter we consider, e.g. the `data-controlled` case.\n",
    "\n",
    "**NOTE:** Let $\\Delta s_i = s_{i+1} - s_i$. Since the individual Neural ODEs are *depth-invariant*, we can just solve the ODEs in $[0,\\Delta s_i]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27c50f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We choose to divide the domain [0,1] in num_pieces=5 intervals\n",
    "num_pieces = 5\n",
    "\n",
    "# Stacked depth-invariant Neural ODEs aka Neural ODEs with piecewise constant weights \n",
    "nde = []\n",
    "for i in range(num_pieces):\n",
    "    nde.append(NeuralODE(nn.Sequential(DataControl(),\n",
    "                                      nn.Linear(4, 4), \n",
    "                                      nn.Tanh(), \n",
    "                                      nn.Linear(4, 2)), solver='dopri5', s_span=torch.linspace(0, 1, 2))) # here we chose _ = 1 . (s_span)\n",
    "model = nn.Sequential(*nde).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c3c63",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=300, max_epochs=350)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e95088",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a247c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,20)\n",
    "trajectory = [model[0].trajectory(X_train, s_span)]\n",
    "for i in range(1, num_pieces):\n",
    "    trajectory.append(\n",
    "        model[i].trajectory(trajectory[i-1][-1,:,:], s_span))\n",
    "                      \n",
    "trajectory = torch.cat(trajectory, 0).detach().cpu() \n",
    "tot_s_span = torch.linspace(0, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df9bda",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(tot_s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c089e04",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51801d02",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(tot_s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be0c75",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Stacked Neural ODEs with Discrete State Transitions\n",
    "\n",
    "These are basically the `Stacked` model where, at the end of an interval $[s_i, s_{i+1}]$, the state is also updated by learned transition maps $g(h, \\omega_i)$ parametrized by a NN, i.e.\n",
    "\n",
    "$$\n",
    "  \\left\\{\n",
    "        \\begin{aligned}\n",
    "             \\dot z &=  f(z(s),\\theta_i) \\quad s\\in[s_i,s_{i+1}]\\\\\n",
    "             z^+ &= g(z(s),\\omega_i) \\quad s = s_{i+1}\n",
    "        \\end{aligned}\n",
    "  \\right.\n",
    "$$\n",
    "\n",
    "**NOTE:** While not standard, this class highlights how Neural ODE variants can be put together hassle-free via torchdyn's API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fb51f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We choose to divide the domain [0,1] in num_pieces=5 intervals\n",
    "num_pieces = 5\n",
    "\n",
    "# stacked depth-invariant Neural ODEs\n",
    "nde = []\n",
    "for i in range(num_pieces):\n",
    "    nde.append(NeuralODE(nn.Sequential(DataControl(),\n",
    "                                      nn.Linear(4, 4), \n",
    "                                      nn.Tanh(), \n",
    "                                      nn.Linear(4, 2)), solver='dopri5'))\n",
    "    # In this case the state \"jump\" is parametrized by a simple linear layer\n",
    "    nde.append(\n",
    "        nn.Linear(2, 2)\n",
    "    )\n",
    "    \n",
    "model = nn.Sequential(*nde).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85ebb9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=200, max_epochs=250)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65872c03",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcef56e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,20)\n",
    "trajectory = [model[0].trajectory(X_train, s_span)]\n",
    "i = 2\n",
    "c = 0\n",
    "while c < num_pieces-1:\n",
    "    x0 = model[i-1](trajectory[c][-1,:,:])\n",
    "    trajectory.append(\n",
    "        model[i].trajectory(x0, s_span))\n",
    "    i += 2\n",
    "    c += 1\n",
    "                      \n",
    "trajectory = torch.cat(trajectory, 0).detach().cpu() \n",
    "tot_s_span = torch.linspace(0, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c557eb4c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(tot_s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3c8dc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023511c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(tot_s_span, trajectory, yn, len(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.046384,
   "end_time": "2021-06-17T12:39:52.317291",
   "environment_variables": {},
   "exception": true,
   "input_path": "tutorials/01_neural_ode_cookbook.ipynb",
   "output_path": "tutorials/01_neural_ode_cookbook.ipynb",
   "parameters": {},
   "start_time": "2021-06-17T12:39:23.270907",
   "version": "2.3.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "149b167de0d34bb19d2b42a462867a37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7edc403926834204a535f29f32ab11ea",
       "placeholder": "",
       "style": "IPY_MODEL_3d19990298ff4aab902b6d79c3395c75",
       "value": " 1/1 [00:00&lt;00:00, 12.13it/s, loss=0.000996, v_num=151]"
      }
     },
     "3d19990298ff4aab902b6d79c3395c75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "42e88b6a8f184fe5aea27524a796ba5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7edc403926834204a535f29f32ab11ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e6d916473ed4e1098d0ef84e221ee26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a6fc6d4e706647bba5caa2d4b99b5f45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ae659a85c83c42fe9613bef07097ec09",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cd126243574a4a27b9b2ea0f3b33afbf",
       "value": 1.0
      }
     },
     "ae659a85c83c42fe9613bef07097ec09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cd126243574a4a27b9b2ea0f3b33afbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e978be3a6a0d4cb4af34adfb7fe2bafb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "f3d08adc32d0462b978dec2b6ba1daa1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f84e1e5544c845f7bef66f7cbd3cf841",
        "IPY_MODEL_a6fc6d4e706647bba5caa2d4b99b5f45",
        "IPY_MODEL_149b167de0d34bb19d2b42a462867a37"
       ],
       "layout": "IPY_MODEL_e978be3a6a0d4cb4af34adfb7fe2bafb"
      }
     },
     "f84e1e5544c845f7bef66f7cbd3cf841": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_42e88b6a8f184fe5aea27524a796ba5f",
       "placeholder": "",
       "style": "IPY_MODEL_9e6d916473ed4e1098d0ef84e221ee26",
       "value": "Epoch 249: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}