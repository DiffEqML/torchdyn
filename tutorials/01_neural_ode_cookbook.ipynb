{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [8]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022454,
     "end_time": "2021-06-16T04:37:56.630771",
     "exception": false,
     "start_time": "2021-06-16T04:37:56.608317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The Cookbook of Neural ODEs\n",
    "\n",
    "Torchdyn implements out-of-the-box a variety of continuous-depth models. In this introductory tutorial, we show how we can switch between model variants with minor effort. We will touch upon the following Neural ODE variants:\n",
    "\n",
    "* **Vanilla** (depth-invariant) (same as the [torchdyn quickstart](./00_quickstart.html) tutorial)\n",
    "* **Vanilla** (depth-variant)\n",
    "* **Galerkin**\n",
    "* **Data-controlled**\n",
    "* **Stacked (piece-wise constant weights)**\n",
    "* **Stacked with discrete state transitions**\n",
    "--------------------------------------\n",
    "\n",
    "For more advanced models check out \n",
    "\n",
    "* [Hamiltonian Neural Networks](./06a_hamiltonian_nn.html)\n",
    "* [Lagrangian Neural Networks](./06b_lagrangian_nn.html)\n",
    "* [Continuous Normalizing Flow](./07_continuous_normalizing_flow.html)\n",
    "* [Graph Neural ODEs](./08_graph_neural_de.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T04:37:56.674345Z",
     "iopub.status.busy": "2021-06-16T04:37:56.674037Z",
     "iopub.status.idle": "2021-06-16T04:37:57.519729Z",
     "shell.execute_reply": "2021-06-16T04:37:57.519973Z"
    },
    "papermill": {
     "duration": 0.87161,
     "end_time": "2021-06-16T04:37:57.520151",
     "exception": false,
     "start_time": "2021-06-16T04:37:56.648541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchdyn.core import NeuralODE\n",
    "from torchdyn.nn import DataControl, DepthCat, Augmenter, GalLinear\n",
    "from torchdyn.datasets import *\n",
    "from torchdyn.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01815,
     "end_time": "2021-06-16T04:37:57.557500",
     "exception": false,
     "start_time": "2021-06-16T04:37:57.539350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data:** we use again the moons dataset (with some added noise) simply because all the models will be effective to solve this easy binary classification problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T04:37:57.596715Z",
     "iopub.status.busy": "2021-06-16T04:37:57.596398Z",
     "iopub.status.idle": "2021-06-16T04:37:57.598398Z",
     "shell.execute_reply": "2021-06-16T04:37:57.598625Z"
    },
    "papermill": {
     "duration": 0.022829,
     "end_time": "2021-06-16T04:37:57.598688",
     "exception": false,
     "start_time": "2021-06-16T04:37:57.575859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = ToyDataset()\n",
    "X, yn = d.generate(n_samples=512, dataset_type='moons', noise=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T04:37:57.637528Z",
     "iopub.status.busy": "2021-06-16T04:37:57.637131Z",
     "iopub.status.idle": "2021-06-16T04:38:00.733088Z",
     "shell.execute_reply": "2021-06-16T04:38:00.733332Z"
    },
    "papermill": {
     "duration": 3.116745,
     "end_time": "2021-06-16T04:38:00.733433",
     "exception": false,
     "start_time": "2021-06-16T04:37:57.616688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['orange', 'blue'] \n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(len(X)):\n",
    "    ax.scatter(X[i,0], X[i,1], s=1, color=colors[yn[i].int()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T04:38:00.807443Z",
     "iopub.status.busy": "2021-06-16T04:38:00.807069Z",
     "iopub.status.idle": "2021-06-16T04:38:05.238099Z",
     "shell.execute_reply": "2021-06-16T04:38:05.237584Z"
    },
    "papermill": {
     "duration": 4.484295,
     "end_time": "2021-06-16T04:38:05.238224",
     "exception": false,
     "start_time": "2021-06-16T04:38:00.753929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train = torch.Tensor(X).to(device)\n",
    "y_train = torch.LongTensor(yn.long()).to(device)\n",
    "train = data.TensorDataset(X_train, y_train)\n",
    "trainloader = data.DataLoader(train, batch_size=len(X), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01823,
     "end_time": "2021-06-16T04:38:05.279332",
     "exception": false,
     "start_time": "2021-06-16T04:38:05.261102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Learner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T04:38:05.320871Z",
     "iopub.status.busy": "2021-06-16T04:38:05.320556Z",
     "iopub.status.idle": "2021-06-16T04:38:05.322563Z",
     "shell.execute_reply": "2021-06-16T04:38:05.322773Z"
    },
    "papermill": {
     "duration": 0.025298,
     "end_time": "2021-06-16T04:38:05.322831",
     "exception": false,
     "start_time": "2021-06-16T04:38:05.297533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model:nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch      \n",
    "        y_hat = self.model(x)   \n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}   \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=0.005)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018254,
     "end_time": "2021-06-16T04:38:05.359449",
     "exception": false,
     "start_time": "2021-06-16T04:38:05.341195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Note:** In this notebook we will consider the depth domain $[0,1]$, i.e. $s\\in[0,1]$. Note that, for most architectures in *static* settings (aka we do not deal with dynamic data) any other depth domain does not actually affect the expressiveness of Neural ODEs, since it can be seen as a rescaled/shifted version of $[0,1]$. Please note that, however, other choices of the depth domain can indeed affect the training phase\n",
    "\n",
    "The depth domain can be accessed and modified through the `s_span` setting of `NeuralDE` instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018421,
     "end_time": "2021-06-16T04:38:05.396347",
     "exception": false,
     "start_time": "2021-06-16T04:38:05.377926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Vanilla Neural ODE (Depth-Invariant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018333,
     "end_time": "2021-06-16T04:38:05.433033",
     "exception": false,
     "start_time": "2021-06-16T04:38:05.414700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$ \\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\dot{z}(s) &= f(z(s), \\theta)\\\\\n",
    "        z(0) &= x\\\\\n",
    "        \\hat y & = z(1)\n",
    "    \\end{aligned}\n",
    "    \\right. \\quad s\\in[0,1]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018219,
     "end_time": "2021-06-16T04:38:05.469616",
     "exception": false,
     "start_time": "2021-06-16T04:38:05.451397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This model is the same used in [torchdyn quickstart](./00_quickstart.html) tutorial. The vector field is parametrized by a neural network $f$ with *static* parameters $\\theta$ and taking as input only the state $h(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T04:38:05.510583Z",
     "iopub.status.busy": "2021-06-16T04:38:05.509913Z",
     "iopub.status.idle": "2021-06-16T04:38:05.521337Z",
     "shell.execute_reply": "2021-06-16T04:38:05.520828Z"
    },
    "papermill": {
     "duration": 0.033242,
     "end_time": "2021-06-16T04:38:05.521433",
     "exception": false,
     "start_time": "2021-06-16T04:38:05.488191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vector field parametrized by a NN\n",
    "f = nn.Sequential(\n",
    "        nn.Linear(2, 64),\n",
    "        nn.Tanh(), \n",
    "        nn.Linear(64, 2))\n",
    "\n",
    "# Neural ODE\n",
    "model = NeuralODE(f, sensitivity='adjoint', solver='dopri5').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T04:38:05.565525Z",
     "iopub.status.busy": "2021-06-16T04:38:05.565266Z",
     "iopub.status.idle": "2021-06-16T04:38:20.643973Z",
     "shell.execute_reply": "2021-06-16T04:38:20.644200Z"
    },
    "papermill": {
     "duration": 15.099901,
     "end_time": "2021-06-16T04:38:20.644298",
     "exception": false,
     "start_time": "2021-06-16T04:38:05.544397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/michael/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | NeuralODE | 322   \n",
      "------------------------------------\n",
      "322       Trainable params\n",
      "0         Non-trainable params\n",
      "322       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, loss=0.929, v_num=134]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, loss=0.171, v_num=134]  \n"
     ]
    }
   ],
   "source": [
    "# train the Neural ODE\n",
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=200, max_epochs=250, progress_bar_refresh_rate=1)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.132675,
     "end_time": "2021-06-16T04:38:20.911207",
     "exception": false,
     "start_time": "2021-06-16T04:38:20.778532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-06-16T04:38:21.180751Z",
     "iopub.status.busy": "2021-06-16T04:38:21.180486Z",
     "iopub.status.idle": "2021-06-16T04:38:21.338298Z",
     "shell.execute_reply": "2021-06-16T04:38:21.337820Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.293902,
     "end_time": "2021-06-16T04:38:21.338553",
     "exception": true,
     "start_time": "2021-06-16T04:38:21.044651",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py:296: UserWarning: t is not on the same device as y0. Coercing to y0.device.\n",
      "  warnings.warn(\"t is not on the same device as y0. Coercing to y0.device.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d1b3fbbd9cff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the data trajectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_span\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/libraries/torchdyn/torchdyn/core/neuralde.py\u001b[0m in \u001b[0;36mtrajectory\u001b[0;34m(self, x, s_span)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[1;32m    191\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prep_odeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         sol = torchdiffeq.odeint(self.defunc, x, s_span,\n\u001b[0m\u001b[1;32m    193\u001b[0m                                  rtol=self.rtol, atol=self.atol, **self.solver)\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0msolution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_advance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torchdiffeq/_impl/rk_common.py\u001b[0m in \u001b[0;36m_before_integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_before_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             first_step = _select_initial_step(self.func, t[0], self.y0, self.order - 1, self.rtol, self.atol,\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# Do nothing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libraries/torchdyn/torchdyn/core/defunc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhorder_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/torchdyn-voYSR01p-py3.8/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)"
     ]
    }
   ],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,100)\n",
    "trajectory = model.trajectory(X_train, s_span).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Vanilla Neural ODE (Depth-Variant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "$$ \\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\dot{z}(s) &= f(s, z(s), \\theta)\\\\\n",
    "        z(0) &= x\\\\\n",
    "        \\hat y & = z(1)\n",
    "    \\end{aligned}\n",
    "    \\right. \\quad s\\in[0,1]\n",
    "$$\n",
    "\n",
    "This model, contemplated by the seminal paper from [[Chen T. Q. et al, 2018]](https://arxiv.org/abs/1806.07366), is usually obtained by concatenating $s$ to the state $h$ as input of $f$, i.e. $f([h(s),s])$. For a simple and flexible implementation we developed a dedicated layer, `DepthCat`, which takes care of automatically concatenating $s$ to the state at each call of the `DEFunc`. The final user only needs to specify concatenation dimension to which $s$ should be appended. Specifically, for an MLP, $h\\in\\mathbb{R}^{batch\\times dims}$ and, thus we should use `DepthCat(1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vector field parametrized by a NN\n",
    "f = nn.Sequential(\n",
    "        DepthCat(1),\n",
    "        nn.Linear(2+1, 64),\n",
    "        nn.Tanh(),\n",
    "        DepthCat(1),\n",
    "        nn.Linear(64+1, 2))\n",
    "\n",
    "# Neural ODE\n",
    "model = NeuralODE(f, sensitivity='adjoint', solver='dopri5').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train the Neural ODE\n",
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=200, max_epochs=250, progress_bar_refresh_rate=1)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,100)\n",
    "trajectory = model.trajectory(X_train, s_span).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Galerkin-Style Neural ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Galerkin-style Neural ODEs proposed in [Massaroli S., Poli M. et al., 2020](https://arxiv.org/abs/2002.08071) make the weights of the neural ODE to be *depth-varying*, i.e. $\\theta=\\theta(s)$ obtaining a model of type\n",
    "\n",
    "$$\n",
    "    \\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\dot{z}(s) &= f(z(s), \\theta(s))\\\\\n",
    "        z(0) &= x\\\\\n",
    "        \\hat y & = z(1)\n",
    "    \\end{aligned}\n",
    "    \\right. \\quad s\\in[0,1]\n",
    "$$\n",
    "\n",
    "where the depth evolution of $\\theta(s)$ is parametrized by a trucated eigenfunction expasion, usually an orthogonal basis of some functional space, i.e.\n",
    "\n",
    "$$\n",
    "    \\forall i \\quad \\theta_i(s) = \\sum_{j=0}^{m}\\gamma_j\\odot\\psi_j(s)\n",
    "$$\n",
    "\n",
    "The model is then trained by optimizing for the eigenvalues $\\gamma_j$. Note that if $\\theta\\in \\mathbb{R}^d$ there will be $d\\times m$ final model's parameters. In this tutorial, we use a 10th-order polynomial expansion to model $\\theta(s)$.\n",
    "\n",
    "**Note:** In `torchdyn 0.1.0` only Fourier `FourierExpansion` and polynomial `PolyExpansion` bases are currently implemented out-of-the-box. Even though a wider selection of bases is planned as a future addition, e.g.  piece-wise constant functions, radial basis functions, etc., users can easily create custom `Expansions` on their own given `torchdyn`'s modular design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vector field parametrized by a NN with \"GalLinear\" layer\n",
    "# notice how DepthCat is still used since Galerkin layers make use of `s` (though in a different way compared to concatenation)\n",
    "f = nn.Sequential(DepthCat(1), \n",
    "                  GalLinear(2, 32, basisfunc=Fourier(5)),\n",
    "                  nn.Tanh(),\n",
    "                  nn.Linear(32, 2))\n",
    "# neural ODE\n",
    "model = NeuralODE(f, sensitivity='adjoint', solver='dopri5').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train the Neural ODE\n",
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=150, max_epochs=200, progress_bar_refresh_rate=1)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,100)\n",
    "trajectory = model.trajectory(X_train, s_span).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Data-Controlled Neural ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Data-controlled neural ODEs, also introduced in [Massaroli S., Poli M. et al., 2020](https://arxiv.org/abs/2002.08071) consist in feeding to the vector field the input data $x$ (the initial condition of the ODE), leading to\n",
    "\n",
    "$$ \\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\dot{z}(s) &= f(z(s), x, \\theta)\\\\\n",
    "        z(0) &= x\\\\\n",
    "        \\hat y & = z(1)\n",
    "    \\end{aligned}\n",
    "    \\right. \\quad s\\in[0,1]\n",
    "$$\n",
    "\n",
    "In this way, the Neural ODE learns a family of vector fields rather than a single one. \n",
    "\n",
    "In practice, we concatenate $x$ to $h$ and simply feed $[h, x]$ to $f$, which should indeed be defined to accomodate the extra $dim(x)$ dimensions. Data-control inputs can be defined at any point in `f` via use of `DataControl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vector field parametrized by a NN which takes as input [h, x]\n",
    "f = nn.Sequential(DataControl(),\n",
    "                  nn.Linear(2+2, 64),\n",
    "                  nn.Tanh(),\n",
    "                  nn.Linear(64, 2))\n",
    "\n",
    "# neural ODE\n",
    "model = NeuralODE(f, sensitivity='adjoint', solver='dopri5').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=150, max_epochs=250)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,100)\n",
    "trajectory = model.trajectory(X_train, s_span).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Stacked Neural ODE (aka Piece-wise constant parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "While looking for an \"easier\" solution than Galererkin Neural ODEs without trading the expressivity of the model, **stacked neural ODEs** may come in handy. Instead of approximating the solution of an infinite-dimensional problem (e.g. Galerkin-style), we can also use piece-wise constant weight functions. Let us subdivide the depth in $N$ intervals\n",
    "    \n",
    "$$\n",
    "        \\mathcal{S} = \\prod_{i=0}^{N}[s_i,s_{i+1}], \\quad s_0 = 0, \\quad s_{N+1}=S  \\quad(\\forall i  \\quad s_i\\leq s_{i+1})\n",
    "$$\n",
    "\n",
    "We can then define the weights as piece-wise constant functions \n",
    "\n",
    "$$\n",
    "        \\forall i  \\quad s\\in[s_i,s_{i+1}]\\Rightarrow\\theta(s) = \\theta_i, \\quad\\theta_i\\in\\{\\theta_1,\\theta_2,\\theta_N\\}\n",
    "$$\n",
    "    \n",
    "The solution of the neural ODE becomes \n",
    "    \n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        z(s) &= x + \\int_0^S f(z(\\tau),\\theta(\\tau))d\\tau \\\\\n",
    "        &= x + \\sum_{i=1}^{N-1}\\int_{s_i}^{s_{i+1}} f(z(\\tau),\\theta_i)d\\tau\n",
    "    \\end{aligned}\n",
    "$$\n",
    "    \n",
    "This is equivalent to stacking $N-1$ neural ODEs with **identical structure** and **disentangled weights**\n",
    "    \n",
    "$$\n",
    "        \\begin{aligned}\n",
    "         \\dot z =  f( z(s),\\theta_i) \\quad s\\in[s_i,s_{i+1}]\n",
    "        \\end{aligned}\n",
    "$$\n",
    "    \n",
    "which are **stacked sequentially** and trained with *classic* adjoint method.\n",
    "\n",
    "In principle, $f$ can be chosen arbitrarily. Hereafter we consider, e.g. the `data-controlled` case.\n",
    "\n",
    "**NOTE:** Let $\\Delta s_i = s_{i+1} - s_i$. Since the individual Neural ODEs are *depth-invariant*, we can just solve the ODEs in $[0,\\Delta s_i]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We choose to divide the domain [0,1] in num_pieces=5 intervals\n",
    "num_pieces = 5\n",
    "\n",
    "# Stacked depth-invariant Neural ODEs aka Neural ODEs with piecewise constant weights \n",
    "nde = []\n",
    "for i in range(num_pieces):\n",
    "    nde.append(NeuralODE(nn.Sequential(DataControl(),\n",
    "                                      nn.Linear(4, 4), \n",
    "                                      nn.Tanh(), \n",
    "                                      nn.Linear(4, 2)), solver='dopri5', s_span=torch.linspace(0, 1, 2))) # here we chose Δ𝑠_𝑖 = 1 ∀𝑖. (s_span)\n",
    "model = nn.Sequential(*nde).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=300, max_epochs=350)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,20)\n",
    "trajectory = [model[0].trajectory(X_train, s_span)]\n",
    "for i in range(1, num_pieces):\n",
    "    trajectory.append(\n",
    "        model[i].trajectory(trajectory[i-1][-1,:,:], s_span))\n",
    "                      \n",
    "trajectory = torch.cat(trajectory, 0).detach().cpu() \n",
    "tot_s_span = torch.linspace(0, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(tot_s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(tot_s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Stacked Neural ODEs with Discrete State Transitions\n",
    "\n",
    "These are basically the `Stacked` model where, at the end of an interval $[s_i, s_{i+1}]$, the state is also updated by learned transition maps $g(h, \\omega_i)$ parametrized by a NN, i.e.\n",
    "\n",
    "$$\n",
    "  \\left\\{\n",
    "        \\begin{aligned}\n",
    "             \\dot z &=  f(z(s),\\theta_i) \\quad s\\in[s_i,s_{i+1}]\\\\\n",
    "             z^+ &= g(z(s),\\omega_i) \\quad s = s_{i+1}\n",
    "        \\end{aligned}\n",
    "  \\right.\n",
    "$$\n",
    "\n",
    "**NOTE:** While not standard, this class highlights how Neural ODE variants can be put together hassle-free via torchdyn's API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We choose to divide the domain [0,1] in num_pieces=5 intervals\n",
    "num_pieces = 5\n",
    "\n",
    "# stacked depth-invariant Neural ODEs\n",
    "nde = []\n",
    "for i in range(num_pieces):\n",
    "    nde.append(NeuralODE(nn.Sequential(DataControl(),\n",
    "                                      nn.Linear(4, 4), \n",
    "                                      nn.Tanh(), \n",
    "                                      nn.Linear(4, 2)), solver='dopri5'))\n",
    "    # In this case the state \"jump\" is parametrized by a simple linear layer\n",
    "    nde.append(\n",
    "        nn.Linear(2, 2)\n",
    "    )\n",
    "    \n",
    "model = nn.Sequential(*nde).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_epochs=200, max_epochs=250)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the data trajectories\n",
    "s_span = torch.linspace(0,1,20)\n",
    "trajectory = [model[0].trajectory(X_train, s_span)]\n",
    "i = 2\n",
    "c = 0\n",
    "while c < num_pieces-1:\n",
    "    x0 = model[i-1](trajectory[c][-1,:,:])\n",
    "    trajectory.append(\n",
    "        model[i].trajectory(x0, s_span))\n",
    "    i += 2\n",
    "    c += 1\n",
    "                      \n",
    "trajectory = torch.cat(trajectory, 0).detach().cpu() \n",
    "tot_s_span = torch.linspace(0, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the depth domain\n",
    "plot_2D_depth_trajectory(tot_s_span, trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in the state-space\n",
    "plot_2D_state_space(trajectory, yn, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trajectories in space-depth\n",
    "plot_2D_space_depth(tot_s_span, trajectory, yn, len(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.045065,
   "end_time": "2021-06-16T04:38:23.943394",
   "environment_variables": {},
   "exception": true,
   "input_path": "tutorials/01_neural_ode_cookbook.ipynb",
   "output_path": "tutorials/01_neural_ode_cookbook.ipynb",
   "parameters": {},
   "start_time": "2021-06-16T04:37:55.898329",
   "version": "2.3.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
