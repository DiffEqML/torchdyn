{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c0fffd-e4ce-497e-ae8d-7845861df680",
   "metadata": {},
   "source": [
    "# Optimal Control Problem\n",
    "\n",
    "We tackle the stabilization of an inverted pendulum via the ***Optimal Energy Shaping*** approach of [CIT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc51a77-1481-44a0-8d14-ecbed4b9b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Uniform, Normal\n",
    "\n",
    "def prior_dist(q_min, q_max, p_min, p_max, device='cpu'):\n",
    "    # uniform \"prior\" distribution of initial conditions x(0)=[q(0),p(0)]\n",
    "    lb = torch.Tensor([q_min, p_min]).to(device)\n",
    "    ub = torch.Tensor([q_max, p_max]).to(device)\n",
    "    return Uniform(lb, ub)\n",
    "\n",
    "def target_dist(mu, sigma, device='cpu'):\n",
    "    # normal target distribution of terminal states x(T)\n",
    "    mu, sigma = torch.Tensor(mu).reshape(1, 2).to(device), torch.Tensor(sigma).reshape(1, 2).to(device)\n",
    "    return Normal(mu, torch.sqrt(sigma))\n",
    "\n",
    "def weighted_log_likelihood_loss(x, target, weight):\n",
    "    # weighted negative log likelihood loss\n",
    "    log_prob = target.log_prob(x)\n",
    "    weighted_log_p = weight * log_prob\n",
    "    return -torch.mean(weighted_log_p.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81433d8c-ac58-481e-bee5-204760b05ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999d585-4d6a-4aed-a172-6a652f4fe282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_trainloader():\n",
    "    # dummy trainloader for Lightning learner. We will sample new initial conditions at each training iteration\n",
    "    dummy = data.DataLoader(\n",
    "        data.TensorDataset(\n",
    "            torch.Tensor(1, 1),\n",
    "            torch.Tensor(1, 1)\n",
    "        ),\n",
    "        batch_size=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16235b51-256f-4c9e-95c0-2ac456fec6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0c5f9b1-a257-47c4-ae50-a6571eac8c09",
   "metadata": {},
   "source": [
    "## Define Controlled System Dynamics\n",
    "\n",
    "We consider a controlled damped inverted pendulum with a torsional spring in the joint with state $(q_t, p_t)$ (joint angle and momentum), described by the Hamiltonian dynamics\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        \\dot q_t &= \\frac{1}{m}p_t \\\\\n",
    "        \\dot p_t &= \\tau_{el} + \\tau_{g} + \\tau_{d} + u_t\n",
    "    \\end{aligned}\n",
    "$$\n",
    "\n",
    "with input torque $u_t$, elastic torque $\\tau_{el} = - k (q - q_r)$, gravitational torque $\\tau_g = mgl\\sin q_t$ and damping (friction) $\\tau_d = \\frac{b}{m} p_t$.\n",
    "\n",
    "Following [CITE] the controller is obtained as \n",
    "\n",
    "$$\n",
    "    u_t = \\gamma_\\theta(q_t, p_t) = -\\nabla_q V_\\theta^*(q_t) - \\frac{1}{m}K(q_t, p_t)p_t\n",
    "$$\n",
    "\n",
    "with $V^*_\\theta:\\mathbb R \\rightarrow\\mathbb R, ~K^*_\\theta:\\mathbb R^2 \\rightarrow\\mathbb R$ being two neural nets with parameters $\\theta$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb2c996-c5a4-47f3-a91b-3294fa1a66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad as grad\n",
    "\n",
    "# physical parameters\n",
    "m, k, l, qr, b, g = 1., 0.5, 1, 0, 0.01, 9.81\n",
    "\n",
    "class ControlledSystem(nn.Module):\n",
    "    # Elastic Pendulum Model\n",
    "    def __init__(self, V, K):\n",
    "        super().__init__()\n",
    "        self.V, self.K, self.n = V, K, 1\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        # Evaluates the closed-loop vector field\n",
    "        with torch.set_grad_enabled(True):\n",
    "            q, p = x[..., :self.n], x[..., self.n:]\n",
    "            q = q.requires_grad_(True)\n",
    "            # compute control action\n",
    "            u = self._energy_shaping(q) + self._damping_injection(x)\n",
    "            # compute dynamics\n",
    "            dxdt = self._dynamics(q, p, u)\n",
    "        return dxdt\n",
    "\n",
    "    def _dynamics(self, q, p, u):\n",
    "        # controlled elastic pendulum dynamics\n",
    "        dqdt = p / m\n",
    "        dpdt = -k * (q - qr) - m * g * l * torch.sin(q) - b * p / m + u\n",
    "        return torch.cat([dqdt, dpdt], 1)\n",
    "\n",
    "    def _energy_shaping(self, q):\n",
    "        # energy shaping control action\n",
    "        dVdx = grad(self.V(q).sum(), q, create_graph=True)[0]\n",
    "        return -dVdx\n",
    "\n",
    "    def _damping_injection(self, x):\n",
    "        # damping injection control action\n",
    "        return -self.K(x) * x[:, self.n:] / m\n",
    "\n",
    "    def _autonomous_energy(self, x):\n",
    "        # Hamiltonian (total energy) of the UNCONTROLLED system\n",
    "        return (m * x[:, 1:] ** 2) / 2. + (k * (x[:, :1] - qr) ** 2) / 2 \\\n",
    "               + m * g * l * (1 - torch.cos(x[:, :1]))\n",
    "\n",
    "    def _energy(self, x):\n",
    "        # Hamiltonian (total energy) of the CONTROLLED system\n",
    "        return (m * x[:, 1:] ** 2) / 2. + (k * (x[:, :1] - qr) ** 2) / 2 \\\n",
    "               + m * g * l * (1 - torch.cos(x[:, :1])) + self.V(x[:, :1])\n",
    "\n",
    "\n",
    "class AugmentedDynamics(nn.Module):\n",
    "    # \"augmented\" vector field to take into account integral loss functions\n",
    "    def __init__(self, f, int_loss):\n",
    "        super().__init__()\n",
    "        self.f = f\n",
    "        self.int_loss = int_loss\n",
    "        self.nfe = 0.\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        x = x[:,:2]\n",
    "        dxdt = self.f(t, x)\n",
    "        dldt = self.int_loss(t, x)\n",
    "        return torch.cat([dxdt, dldt], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b67d96-74f1-4642-a5fe-11b444d9b55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930cec70-788b-4669-be3e-038397825ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a317365-3335-4774-a0ff-1f90624eb848",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vq/9b19jynj4jdgq5_1g40nx2w40000gn/T/ipykernel_889/1639618049.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprior_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_trainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_log_likelihood_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mControlledSystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAugmentedDynamics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearners\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnergyShapingLearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from sys import path ; path.append('../../')\n",
    "from torchdyn.numerics import odeint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from src.control.utils import prior_dist, target_dist, dummy_trainloader, weighted_log_likelihood_loss\n",
    "from src.control.models import ControlledSystem, AugmentedDynamics\n",
    "from src.control.learners import EnergyShapingLearner\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751315e1-d5da-49a7-aa61-de2bbb9deebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
