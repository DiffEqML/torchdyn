{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows imports from parent folders\n",
    "from prep import prep_nbook\n",
    "prep_nbook()\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torchdiffeq\n",
    "\n",
    "from torchdyn.models import *; from torchdyn.data_utils import *\n",
    "from torchdyn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification with Neural ODEs and variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we explore standard image classification on MNIST and CIFAR10 with convolutional neural ODE variants.\n",
    "* Depth-invariant neural ODE\n",
    "* Galerkin neural ODE (GalNODE)\n",
    "* Galerkin neural ODE with adjoint loss\n",
    "In the following notebooks we'll explore `augmentation` strategies that can be easily applied to the models below with the flexible `torchdyn` API. Here, we use simple `0-augmentation` (the ANODE model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "size=28\n",
    "path_to_data='../data/mnist_data'\n",
    "\n",
    "all_transforms = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(path_to_data, train=True, download=True,\n",
    "                            transform=all_transforms)\n",
    "test_data = datasets.MNIST(path_to_data, train=False,\n",
    "                           transform=all_transforms)\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, targets):\n",
    "    \"\"\"Accuracy metric\"\"\"\n",
    "    _, preds = torch.max(preds, dim=1)\n",
    "    acc = 100*(preds == targets).float().mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model:nn.Module, lr=1e-3):\n",
    "        super().__init__()\n",
    "        defaults.update(settings)\n",
    "        self.lr = lr\n",
    "        self.model = model\n",
    "        self.c = 0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch   \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = self.model(x)   \n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}   \n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = self(x)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        return {'test_loss': nn.CrossEntropyLoss()(y_hat, y), 'test_accuracy': acc}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_accuracy'] for x in outputs]).mean()\n",
    "        logs = {'test_loss': avg_loss}\n",
    "        return {'avg_test_loss': avg_loss, 'avg_test_accuracy': avg_acc,\n",
    "                'log': logs, 'progress_bar': logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST (Depth-Invariant Neural ODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {'type':'classic', 'controlled':False, 'solver':'dopri5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = DEFunc(nn.Sequential(nn.Conv2d(6, 6, 3, padding=1),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Conv2d(6, 6, 3, padding=1),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Conv2d(6, 6, 3, padding=1) \n",
    "                             )).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralDE = NeuralDE(func, settings).to(device)\n",
    "\n",
    "model = nn.Sequential(Augmenter(augment_dims=5),\n",
    "                      nn.BatchNorm2d(6),\n",
    "                      neuralDE,\n",
    "                      nn.Conv2d(6, 1, 3, padding=1),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(28*28, 10)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = WandbLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "   | Name               | Type        | Params\n",
      "-----------------------------------------------\n",
      "0  | model              | Sequential  | 8 K   \n",
      "1  | model.0            | Augmenter   | 0     \n",
      "2  | model.1            | BatchNorm2d | 12    \n",
      "3  | model.2            | NeuralDE    | 990   \n",
      "4  | model.2.defunc     | DEFunc      | 990   \n",
      "5  | model.2.defunc.m   | Sequential  | 990   \n",
      "6  | model.2.defunc.m.0 | Conv2d      | 330   \n",
      "7  | model.2.defunc.m.1 | Tanh        | 0     \n",
      "8  | model.2.defunc.m.2 | Conv2d      | 330   \n",
      "9  | model.2.defunc.m.3 | Tanh        | 0     \n",
      "10 | model.2.defunc.m.4 | Conv2d      | 330   \n",
      "11 | model.2.adjoint    | Adjoint     | 0     \n",
      "12 | model.3            | Conv2d      | 55    \n",
      "13 | model.4            | Flatten     | 0     \n",
      "14 | model.5            | Linear      | 7 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8436ee51825d4fcc9eed7dfbbee48ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jyp/.local/share/virtualenvs/GNODE--9w4TJnR/lib/python3.7/site-packages/pytorch_lightning/utilities/warnings.py:18: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/jyp/.local/share/virtualenvs/GNODE--9w4TJnR/lib/python3.7/site-packages/pytorch_lightning/utilities/warnings.py:18: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(model)\n",
    "trainer = pl.Trainer(min_nb_epochs=1, max_nb_epochs=2)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 epochs are not enough. Feel free to keep training and using all kinds of scheduling and optimization tricks :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jyp/.local/share/virtualenvs/GNODE--9w4TJnR/lib/python3.7/site-packages/pytorch_lightning/utilities/warnings.py:18: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0f08ca29a046ad9caec0b3c38087f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing', layout=Layout(flex='2'), max=157.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'avg_test_accuracy': 95.87977600097656,\n",
      " 'avg_test_loss': 0.1398904025554657,\n",
      " 'test_loss': 0.1398904025554657}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST (GalNODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {'type':'classic', 'controlled':False, 'solver':'dopri5', 'return_traj':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = DEFunc(nn.Sequential(DepthCat(1),\n",
    "                            GalConv2d(6, 6, 3, padding=1, expfunc=FourierExpansion, n_harmonics=4, n_eig=1),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Conv2d(6, 6, 3, padding=1),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Conv2d(6, 6, 3, padding=1) \n",
    "                           )                       \n",
    "             ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralDE = NeuralDE(func, settings).to(device)\n",
    "\n",
    "model = nn.Sequential(Augmenter(augment_dims=5),\n",
    "                      nn.BatchNorm2d(6),\n",
    "                      neuralDE,\n",
    "                      nn.Conv2d(6, 1, 3, padding=1),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(28*28, 10)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = WandbLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "   | Name               | Type        | Params\n",
      "-----------------------------------------------\n",
      "0  | model              | Sequential  | 11 K  \n",
      "1  | model.0            | Augmenter   | 0     \n",
      "2  | model.1            | BatchNorm2d | 12    \n",
      "3  | model.2            | NeuralDE    | 3 K   \n",
      "4  | model.2.defunc     | DEFunc      | 3 K   \n",
      "5  | model.2.defunc.m   | Sequential  | 3 K   \n",
      "6  | model.2.defunc.m.0 | DepthCat    | 0     \n",
      "7  | model.2.defunc.m.1 | GalConv2d   | 2 K   \n",
      "8  | model.2.defunc.m.2 | Tanh        | 0     \n",
      "9  | model.2.defunc.m.3 | Conv2d      | 330   \n",
      "10 | model.2.defunc.m.4 | Tanh        | 0     \n",
      "11 | model.2.defunc.m.5 | Conv2d      | 330   \n",
      "12 | model.2.adjoint    | Adjoint     | 0     \n",
      "13 | model.3            | Conv2d      | 55    \n",
      "14 | model.4            | Flatten     | 0     \n",
      "15 | model.5            | Linear      | 7 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf249a281fa4520ba59285a68312aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(model, lr=1e-3)\n",
    "trainer = pl.Trainer(min_nb_epochs=1, max_nb_epochs=2)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jyp/.local/share/virtualenvs/GNODE--9w4TJnR/lib/python3.7/site-packages/pytorch_lightning/utilities/warnings.py:18: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9ca16c17614c128174ee6968ca2d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing', layout=Layout(flex='2'), max=157.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'avg_test_accuracy': 91.18232727050781,\n",
      " 'avg_test_loss': 0.3063780665397644,\n",
      " 'test_loss': 0.3063780665397644}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST (GalNODE, integral adjoint loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will train a MNIST classifier using an integral loss. This, as will be seen later, improves the rate of convergence of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = nn.Sequential(nn.Conv2d(6, 1, 3, padding=1),\n",
    "                          nn.Flatten(),\n",
    "                          nn.Linear(28*28, 10)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cost(nn.Module):\n",
    "    def __init__(self, criterion, predictor):\n",
    "        super().__init__()\n",
    "        # y needs to return targets at each value of `s`. Since for classification the target\n",
    "        # is static, it simply returns the batch labels `y`.\n",
    "        self.y = None\n",
    "        self.criterion, self.predictor = criterion, predictor\n",
    "    def forward(self, s, x):\n",
    "        loss = self.criterion(self.predictor(x), self.y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Cost(nn.CrossEntropyLoss(), predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {'type':'classic', 'controlled':False, 'backprop_style':'integral_adjoint', 'cost':c,\n",
    "            'solver':'dopri5', 'return_traj':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = DEFunc(nn.Sequential(DepthCat(1),\n",
    "                            GalConv2d(6, 6, 3, padding=1, expfunc=FourierExpansion, n_harmonics=4, n_eig=1),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Conv2d(6, 6, 3, padding=1),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Conv2d(6, 6, 3, padding=1) \n",
    "                           )                       \n",
    "             ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralDE = NeuralDE(func, settings).to(device)\n",
    "\n",
    "\n",
    "model = nn.Sequential(Augmenter(augment_dims=5),\n",
    "                      neuralDE,\n",
    "                      predictor).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine Learner to account for the `integral loss` case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model:nn.Module, lr):\n",
    "        super().__init__()\n",
    "        defaults.update(settings)\n",
    "        self.lr = lr\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch   \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # this line serves a specific purpose: set the integral loss target at `y` throughout the depth--flow\n",
    "        c.y = y\n",
    "        y_hat = self.model(x)   \n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}   \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=0.005)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = self(x)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        return {'test_loss': nn.CrossEntropyLoss()(y_hat, y), 'test_accuracy': acc}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_accuracy'] for x in outputs]).mean()\n",
    "        logs = {'test_loss': avg_loss}\n",
    "        return {'avg_test_loss': avg_loss, 'avg_test_accuracy': avg_acc,\n",
    "                'log': logs, 'progress_bar': logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-5)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return trainloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "   | Name               | Type       | Params\n",
      "----------------------------------------------\n",
      "0  | model              | Sequential | 11 K  \n",
      "1  | model.0            | Augmenter  | 0     \n",
      "2  | model.1            | NeuralDE   | 3 K   \n",
      "3  | model.1.defunc     | DEFunc     | 3 K   \n",
      "4  | model.1.defunc.m   | Sequential | 3 K   \n",
      "5  | model.1.defunc.m.0 | DepthCat   | 0     \n",
      "6  | model.1.defunc.m.1 | GalConv2d  | 2 K   \n",
      "7  | model.1.defunc.m.2 | Tanh       | 0     \n",
      "8  | model.1.defunc.m.3 | Conv2d     | 330   \n",
      "9  | model.1.defunc.m.4 | Tanh       | 0     \n",
      "10 | model.1.defunc.m.5 | Conv2d     | 330   \n",
      "11 | model.1.adjoint    | Adjoint    | 0     \n",
      "12 | model.2            | Sequential | 7 K   \n",
      "13 | model.2.0          | Conv2d     | 55    \n",
      "14 | model.2.1          | Flatten    | 0     \n",
      "15 | model.2.2          | Linear     | 7 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb68a3ec6a94f5d8e4d0450f9be684c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = WandbLogger()\n",
    "learn = Learner(model, lr=1e-3)\n",
    "trainer = pl.Trainer(min_nb_epochs=1, max_nb_epochs=2)\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jyp/.local/share/virtualenvs/GNODE--9w4TJnR/lib/python3.7/site-packages/pytorch_lightning/utilities/warnings.py:18: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e2b1d3d89d4634b5c83c1cc4b2a0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing', layout=Layout(flex='2'), max=157.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'avg_test_accuracy': 89.79896545410156,\n",
      " 'avg_test_loss': 0.3477240204811096,\n",
      " 'test_loss': 0.3477240204811096}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 (Depth-Invariant Neural ODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "size=32\n",
    "path_to_data='../data/cifar10_data'\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "train_data = datasets.CIFAR10(path_to_data, train=True, download=True,\n",
    "                              transform=transform_train)\n",
    "test_data = datasets.CIFAR10(path_to_data, train=False,\n",
    "                             transform=transform_test)\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {'type':'classic', 'backprop_style': 'autograd', 'return_traj':False, 'controlled':False, 'solver':'dopri5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = DEFunc(nn.Sequential(nn.Conv2d(6, 6, 3, padding=1),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Conv2d(6, 6, 3, padding=1)                       \n",
    "                             )).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralDE = NeuralDE(func, settings).to(device)\n",
    "\n",
    "model = nn.Sequential(Augmenter(augment_dims=3),\n",
    "                      neuralDE,\n",
    "                      nn.Conv2d(6, 1, 3, padding=1),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(1024, 10)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "   | Name               | Type       | Params\n",
      "----------------------------------------------\n",
      "0  | model              | Sequential | 10 K  \n",
      "1  | model.0            | Augmenter  | 0     \n",
      "2  | model.1            | NeuralDE   | 660   \n",
      "3  | model.1.defunc     | DEFunc     | 660   \n",
      "4  | model.1.defunc.m   | Sequential | 660   \n",
      "5  | model.1.defunc.m.0 | Conv2d     | 330   \n",
      "6  | model.1.defunc.m.1 | Tanh       | 0     \n",
      "7  | model.1.defunc.m.2 | Conv2d     | 330   \n",
      "8  | model.1.adjoint    | Adjoint    | 0     \n",
      "9  | model.2            | Conv2d     | 55    \n",
      "10 | model.3            | Flatten    | 0     \n",
      "11 | model.4            | Linear     | 10 K  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8a9562059c4c6e94d74c22f9be92d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = WandbLogger()\n",
    "learn = Learner(model, lr=1e-3)\n",
    "trainer = pl.Trainer(min_nb_epochs=1, max_nb_epochs=2)\n",
    "trainer.fit(learn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
